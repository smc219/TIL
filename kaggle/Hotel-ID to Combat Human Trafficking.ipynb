{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n!python pytorch-xla-env-setup.py --version nightly --apt-packages libomp5 libopenblas-dev\n!pip install https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.6-cp37-cp37m-linux_x86_64.whl\n!pip install torch==1.6","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# VERSION = \"20200318\"\n# !curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n# !python pytorch-xla-env-setup.py --version $VERSION","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch_xla\nimport torch_xla.core.xla_model as xm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nfrom PIL import Image\nimport os\n\nimport torch\nimport torch.nn as nn\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.utils.data import Subset\nimport cv2\nimport time\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"!ls ../input/d/smc219/data-hotel-model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH = 1000\nEPOCHS = 100\n\n\nLR = 0.01\nIM_SIZE = 32\nDEVICE = xm.xla_device()\n# DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\npath = '../input/hotelid2021fgvc8-728x1024/hotel-id-2021-fgvc8_728x1024/'\nval_path = '../input/hotel-id-2021-fgvc8/'\nTRAIN_DIR = path + 'train_images/'\nTEST_DIR = path + 'test_images/'\nprint(DEVICE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# switch to val path\n# path = val_path","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(path+'train.csv')\ntrain_df\npath = val_path","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import preprocessing\n\nle = preprocessing.LabelEncoder()\nle.fit(train_df['chain'])\ntrain_df['label'] = le.transform(train_df['chain'])\ntrain_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for Inference\n\nclass_map = dict(sorted(train_df[['label', 'chain']].values.tolist()))\nclass_map","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Transform = transforms.Compose(\n    [transforms.ToTensor(),\n    transforms.Resize((IM_SIZE, IM_SIZE)),\n    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class GetData(Dataset):\n    def __init__(self, Dir, FNames, Labels, Transform):\n        self.dir = Dir\n        self.fnames = FNames\n        self.transform = Transform\n        self.labels = Labels         \n        \n    def __len__(self): \n        return len(self.fnames)\n\n    def __getitem__(self, index):       \n#         x = Image.open(os.path.join(self.dir, self.fnames[index]))\n        x = np.array(cv2.imread(os.path.join(self.dir, self.fnames[index]), cv2.IMREAD_COLOR))\n        if \"train\" in self.dir:             \n            return self.transform(x), self.labels[index]\n        elif \"test\" in self.dir:            \n            return self.transform(x), self.fnames[index]","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['chain_image'] = train_df['chain'].astype(str) + '/' + train_df['image']\ntrain_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_val_dataset(dataset, val_split=0.25):\n    train_idx, val_idx = train_test_split(list(range(len(dataset))), test_size=val_split)\n    datasets = {}\n    datasets['train'] = Subset(dataset, train_idx)\n    datasets['val'] = Subset(dataset, val_idx)\n    return datasets","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tr_df = train_df[:10000]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\ntrain_df['chain_image'] = train_df['chain'].astype(str) + '/' + train_df['image']\ntr_df = train_df\n\nprint(len(tr_df))\nX_Train, Y_Train = tr_df['chain_image'].values, tr_df['label'].values\n\n# X_Train = train_df['chain_image'].values\n# Y_Train = train_df['label'].values\n\ntrainset = GetData(TRAIN_DIR, X_Train, Y_Train, Transform)\ntotalset = train_val_dataset(trainset)\ntrain_loader = DataLoader(totalset['train'], batch_size=BATCH, shuffle=True)\nval_loader = DataLoader(totalset['val'], batch_size=BATCH, shuffle=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# next(iter(val_loader))[0].shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[train_df['label'] == 16]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NUM_CL = len(train_df['chain'].value_counts())\nNUM_CL","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nmodel = torchvision.models.resnet50()\nmodel.fc = nn.Linear(2048, NUM_CL, bias=True)\n# state_dict = xser.load('../input/d/smc219/data-hotel-model/22.pth')\nmodel.load_state_dict(torch.load('../input/d/smc219/data-hotel-model/22.pth', map_location=torch.device('cpu')))\n# model.load_state_dict(state_dict)\nmodel = model.to(DEVICE)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=LR)\nprint(model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# s_ls = []\n# correct = 0\n# total = 0\n# with torch.no_grad():\n#     model.eval()\n#     for image, fname in val_loader: \n       \n#         image = image.to(DEVICE)\n    \n#         logits = model(image)    \n#         if total == 0: print(logits)\n        \n#         ps = torch.exp(logits)        \n#         _, top_class = ps.topk(1, dim=1)\n#         if total == 0: print(ps)\n#         total += image.size()[0]\n#         for i in range(len(top_class)):\n#             pred = top_class[i]\n#             correct += (pred == fname[i]).sum().float()\n            \n            \n# print(correct / 250 * 100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(correct * 100 / total)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(correct)\n# print(total)\n# print(output.shape)\n# print(labels.shape)\n# _, predicted = torch.max(outputs.data, 1)\n# print(predicted.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.train()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nmodel.to(DEVICE)\nfor epoch in range(EPOCHS):\n    tr_loss = 0.0\n    \n    start = time.time()\n    model = model.train()\n\n    for i, (images, labels) in enumerate(train_loader):   \n        start = time.time()\n        images = images.to(DEVICE)\n        labels = labels.to(DEVICE)       \n        logits = model(images.float())       \n        loss = criterion(logits, labels)\n        optimizer.zero_grad()\n\n            \n        optimizer.step()\n        \n        \n        \n        tr_loss += loss.detach().item()\n        print(\"{} time : {}\".format(i, time.time() - start))\n    torch.save(model.state_dict(), './2021_0519' + str(epoch) + '.pth')\n    model.eval()\n    print('Epoch: %d | Loss: %.4f'%(epoch, tr_loss / i))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model.state_dict(), './2021_0519_fin.pth')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
